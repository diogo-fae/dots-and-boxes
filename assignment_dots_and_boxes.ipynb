{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Search: Playing Dots and Boxes\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Total Points: Undegraduates 100, graduate students 110\n",
    "\n",
    "Complete this notebook and submit it. The notebook needs to be a complete project report with your implementation, documentation including a short discussion of how your implementation works and your design choices, and experimental results (e.g., tables and charts with simulation results) with a short discussion of what they mean. Use the provided notebook cells and insert additional code and markdown cells as needed.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "You will implement different versions of agents that play the game Dots and Boxes:\n",
    "\n",
    "> \"Dots and Boxes is a pencil-and-paper game for two players. The game starts with an empty grid of dots. Usually two players take turns adding a single horizontal or vertical line between two unjoined adjacent dots. A player who completes the fourth side of a 1x1 box earns one point and takes another turn. A point is typically recorded by placing a mark that identifies the player in the box, such as an initial. The game ends when no more lines can be placed. The winner is the player with the most points. The board may be of any size grid.\" (see [Dots and Boxes on Wikipedia](https://en.wikipedia.org/wiki/Dots_and_Boxes))\n",
    "\n",
    "You can play Dots and Boxes [here](https://www.math.ucla.edu/~tom/Games/dots&boxes.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Defining the Search Problem [10 point]\n",
    "\n",
    "Define the components of the search problem associated with this game:\n",
    "\n",
    "* **Initial state**\n",
    "  * Board with no lines connecting any dots.\n",
    "* **Actions**\n",
    "  * Draw a line connecting two dots.\n",
    "* **Transition model**\n",
    "  * results(s, a) = sâ€™\n",
    "  * Drawing a line will result in the board having a new line connecting two previously unconnected dots. The transition model takes care of initials in boxes.\n",
    "* **Test for the terminal state**\n",
    "  * ----------------------------------------------------------------------------------------------------------------------------------------\n",
    "* **Utility for terminal states**\n",
    "  * ----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**n = number of dots in a column of the board**\n",
    "**k = n - 1**\n",
    "1. How big is the state space? Give an estimate and explain it.<br/>\n",
    "    The state space must account for all lines and know if they are drawn or not, which can be calculated with the following formula: 2^(n*k + n*k).<br/>\n",
    "    It must also account for the drawn boxes and who owns them (the player or the opponent), which can be found with: 2^(k^2).<br/>\n",
    "    Therefore, the total state spaace is **2^(n*k + n*k) + 2^(k^2)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is the game tree that minimax search will go through? Give an estimate and explain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here.------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Game Environment and Random Agent [30 point]\n",
    "\n",
    "You need to think about a data structure to represent the board meaning he placed lines and who finished what box. There are many options. Let's represent the board using a simple dictionary where `n` and `m` represents the number of dots horizontaly and vertically, respectively. Everybody needs to use the same representation so we can let agents play against each other later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "board = {\n",
    "    'n': 4,  ### hoizontal dots\n",
    "    'm': 4,   ### vertical dots\n",
    "    1: 0,   ### number of squares for player 1\n",
    "    -1: 0    ### number of squares for player 2\n",
    "}\n",
    "\n",
    "def empty_board():\n",
    "    return {\n",
    "            'n': 4,  ### hoizontal dots\n",
    "            'm': 4,   ### vertical dots\n",
    "            1: 0,   ### number of squares for player 1\n",
    "            -1: 0   ### number of squares for player 2\n",
    "            }\n",
    "    \n",
    "def empty_small():\n",
    "    return {\n",
    "            'n': 3,  ### hoizontal dots\n",
    "            'm': 3,   ### vertical dots\n",
    "            1: 0,   ### number of squares for player 1\n",
    "            -1: 0   ### number of squares for player 2\n",
    "            }\n",
    "\n",
    "def full_board():\n",
    "    board = empty_board()\n",
    "    for row in range(board['n']):\n",
    "        for col in range(board['m']):\n",
    "            if col < board['m']-1:\n",
    "                draw_line(board, 'h', row+1, col+1, np.random.choice((-1, 1)))\n",
    "            if row >= 1:\n",
    "                draw_line(board, 'v', row+1, col+1, np.random.choice((-1, 1)))\n",
    "    return board\n",
    "\n",
    "def draw_line(board, orientation, row, col, player):\n",
    "    \"\"\"\n",
    "    Place a line on an exiting board.\n",
    "       \n",
    "    Parameters\n",
    "    ----------\n",
    "    board: dict\n",
    "        the board\n",
    "    orientation: str\n",
    "        either 'h' or 'v' for horizontal or vertical\n",
    "    row, col: int\n",
    "        index of the starting dot for the line (starting with 0)\n",
    "    player: str\n",
    "        Either -1 or +1, representing the player adding the line\n",
    "    \"\"\"\n",
    "    if orientation not in ['h', 'v']:\n",
    "        return False\n",
    "    \n",
    "    if player != -1 and player != 1:\n",
    "        return False\n",
    "        \n",
    "    if row < 0 or col < 0:\n",
    "        return False\n",
    "        \n",
    "    if row >= (board['n']+1) + (orientation == 'v') or col >= (board['m']+1) + (orientation == 'h'):\n",
    "        return False\n",
    "        \n",
    "    if (orientation, row, col) in board:\n",
    "        return False\n",
    "    \n",
    "    board[(orientation, row, col)] = True\n",
    "    \n",
    "    # Check if the line closes a box\n",
    "    line = (orientation, row, col)\n",
    "    \n",
    "    # Go through all cases\n",
    "    if line[0] == 'h':\n",
    "        # Case 1: horizontal line at bottom\n",
    "        if ('v', line[1]+1, line[2]) in board and ('v', line[1]+1, line[2]+1) in board and ('h', line[1]+1, line[2]) in board:\n",
    "            # Add point to player\n",
    "            board[player] += 1\n",
    "            # Add box ownership to player\n",
    "            board[(line[1]+1, line[2])] = player\n",
    "        \n",
    "        # Case 2: horizontal line at top\n",
    "        if ('v', line[1], line[2]) in board and ('v', line[1], line[2]+1) in board and ('h', line[1]-1, line[2]) in board:\n",
    "            # Add point to player\n",
    "            board[player] += 1\n",
    "            # Add box ownership to player\n",
    "            board[(line[1], line[2])] = player\n",
    "    \n",
    "    if line[0] == 'v':\n",
    "        # Case 3: vertical line at left\n",
    "        if ('h', line[1], line[2]) in board and ('v', line[1], line[2]+1) in board and ('h', line[1]-1, line[2]) in board:\n",
    "            # Add point to player\n",
    "            board[player] += 1\n",
    "            # Add box ownership to player\n",
    "            board[(line[1], line[2])] = player\n",
    "        \n",
    "        # Case 4: vertical line at right\n",
    "        if ('h', line[1], line[2]-1) in board and ('v', line[1], line[2]-1) in board and ('h', line[1]-1, line[2]-1) in board:\n",
    "            # Add point to player\n",
    "            board[player] += 1\n",
    "            # Add box ownership to player\n",
    "            board[(line[1], line[2]-1)] = player\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to display the board. **Bonus point: Post your visualization code with an example output to the discussion board. The best visualization will earn you bonus participation points in this class.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "def print_board(board):\n",
    "    n = board['n']\n",
    "    m = board['m']\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(-0.5, m-0.5)\n",
    "    ax.set_ylim(-0.5, n-0.5)\n",
    "    \n",
    "    # Draw dots\n",
    "    for row in range(n):\n",
    "        for col in range(m):\n",
    "            if (row, col) in board:\n",
    "                ax.scatter(row, col, s=100, marker='o', color='black')\n",
    "            else:\n",
    "                ax.scatter(row, col, s=100, marker='o', color='black')\n",
    "     \n",
    "    # Draw lines\n",
    "    for line in board:\n",
    "        # print(line)\n",
    "        if line != 'n' and line != 'm' and line != -1 and line != 1:\n",
    "            # print(line)\n",
    "            if len(line) > 2:\n",
    "                # Draw Horizontal line\n",
    "                if line[0] == 'h':\n",
    "                    l = mlines.Line2D([line[2]-1,line[2]], [line[1]-1,line[1]-1], color='black')\n",
    "                    # l = mlines.Line2D([line[1],line[1]], [line[2],line[2]+1], color='black')\n",
    "                    ax.add_line(l)\n",
    "                # Draw Vertical line\n",
    "                else:\n",
    "                    l = mlines.Line2D([line[2]-1,line[2]-1], [line[1]-1,line[1]-2], color='black')\n",
    "                    # l = mlines.Line2D([line[1],line[1]-1], [line[2],line[2]], color='black')\n",
    "                    ax.add_line(l)\n",
    "    \n",
    "    # Check for boxes\n",
    "    # Boxes are stored in board with (row, col) as key and player (1 or -1) as value\n",
    "    for box in board:\n",
    "        if box != 'n' and box != 'm' and box != -1 and box != 1:\n",
    "            if len(box) == 2:\n",
    "                if board[(box[0], box[1])] == 1:\n",
    "                    ax.add_patch(plt.Rectangle((box[1]-1, box[0]-2), 1, 1, color='b'))\n",
    "                else:\n",
    "                    ax.add_patch(plt.Rectangle((box[1]-1, box[0]-2), 1, 1, color='r'))\n",
    "    \n",
    "    # Print results   \n",
    "    print('Results:')\n",
    "    print('         -1:', board[-1])\n",
    "    print('          1:', board[1])\n",
    "    \n",
    "    # Set up plot to start at (1, 1)\n",
    "    x = []\n",
    "    y = []\n",
    "    for row in range(board['n']):\n",
    "        # x.append(row)\n",
    "        x.append(row+1)\n",
    "    for col in range(board['m']):\n",
    "        # y.append(col)\n",
    "        y.append(col+1)\n",
    "    default_x_ticks = range(len(x))\n",
    "    plt.xticks(default_x_ticks, x)\n",
    "    default_y_ticks = range(len(y))\n",
    "    plt.yticks(default_y_ticks, y)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "         -1: 5\n",
      "          1: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of a board\n",
    "print_board(full_board())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement helper functions for:\n",
    "\n",
    "* The transition model $result(s, a)$.\n",
    "* The utility function $utility(s)$.\n",
    "* Check for terminal states $terminal(s)$.\n",
    "* A check for available actions in each state $actions(s)$.\n",
    "\n",
    "__Notes:__\n",
    "* Make sure that all these functions work with boards of different sizes (number of columns and rows as stored in the board).\n",
    "* The result function evaluates if the player closed a box and needs to store that information on the board. Add elements of the form `(row,col): player` to the board dictionary. `row` and `col` are the coordinates for the box and `player` is +1 or -1 representing the player. For example `(0,0): -1` means that the top-left box belongs to the other player. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closed_box(state, action, player=1):\n",
    "    \"\"\"\n",
    "    Check if the action closed a box, return True if it did.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    board: dict\n",
    "        The board\n",
    "    action: list\n",
    "        List describing the action\n",
    "        action[0]: orientation - 'h' or 'v'\n",
    "        action[1]: row\n",
    "        action[2]: column\n",
    "    \"\"\"\n",
    "    \n",
    "    state = state.copy()\n",
    "    \n",
    "    draw_line(state, action[0], action[1], action[2], player)\n",
    "    \n",
    "    if action[0] == 'h':\n",
    "        # Case 1: horizontal line at bottom\n",
    "        if ('v', action[1]+1, action[2]) in state and ('v', action[1]+1, action[2]+1) in state and ('h', action[1]+1, action[2]) in state:\n",
    "            # print(action, ' Case 1')\n",
    "            return True\n",
    "        # Case 2: horizontal line at top\n",
    "        if ('v', action[1], action[2]) in state and ('v', action[1], action[2]+1) in state and ('h', action[1]-1, action[2]) in state:\n",
    "            # print(action, ' Case 2')\n",
    "            return True\n",
    "    if action[0] == 'v':\n",
    "        # Case 3: vertical line at left\n",
    "        if ('h', action[1], action[2]) in state and ('v', action[1], action[2]+1) in state and ('h', action[1]-1, action[2]) in state:\n",
    "            # print(action, ' Case 3')\n",
    "            return True\n",
    "        # Case 4: vertical line at right\n",
    "        if ('h', action[1], action[2]-1) in state and ('v', action[1], action[2]-1) in state and ('h', action[1]-1, action[2]-1) in state:\n",
    "            # print(action, ' Case 4')\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def result(state, action, player=1, agent=random_player):\n",
    "    '''\n",
    "    Place a line on the state received. Keeps placing lines if player\n",
    "    closes a box. Only stops once the new line does not close a box or\n",
    "    there are no more lines to place.\n",
    "       \n",
    "    Parameters\n",
    "    ----------\n",
    "    state: dict\n",
    "        the board\n",
    "    action: tuple\n",
    "        (orientation, row, col)\n",
    "    player: int\n",
    "        -1 or +1 representing the player adding a line\n",
    "    agent: dots and boxes agent\n",
    "        agent that will be playing\n",
    "    '''\n",
    "    \n",
    "    state = state.copy()\n",
    "    \n",
    "    while True:\n",
    "        if action is None:\n",
    "            return state\n",
    "        \n",
    "        # print(action, ' Closed: ', closed_box(state, action))\n",
    "        \n",
    "        if not closed_box(state, action):\n",
    "            draw_line(state, action[0], action[1], action[2], player)\n",
    "            return state\n",
    "        \n",
    "        draw_line(state, action[0], action[1], action[2], player)\n",
    "        \n",
    "        action = agent(state, player)\n",
    "    \n",
    "    # return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_win(state, player=1):\n",
    "    '''\n",
    "    Checks the winner of the state received.\n",
    "       \n",
    "    Parameters\n",
    "    ----------\n",
    "    state: dict\n",
    "        the board\n",
    "    player: int\n",
    "        -1 or +1 representing the player adding a line\n",
    "    Returns a string for win, draw, or loss\n",
    "    '''\n",
    "        \n",
    "    playerPoints = 0\n",
    "    opponentPoints = 0\n",
    "    for dots in state:\n",
    "        if dots != 'n' and dots != 'm' and dots != -1 and dots != 1:\n",
    "            if len(dots) == 2:\n",
    "                if state[dots] == player:\n",
    "                    playerPoints += 1\n",
    "                elif state[dots] == -player:\n",
    "                    opponentPoints += 1\n",
    "    \n",
    "    if (playerPoints + opponentPoints) < ((state['n']-1)*(state['m']-1)):\n",
    "        return 'next'        \n",
    "    else:\n",
    "        if playerPoints > opponentPoints:\n",
    "            return 'win'\n",
    "        elif playerPoints < opponentPoints:\n",
    "            return 'loss'\n",
    "        elif playerPoints == opponentPoints:\n",
    "            return 'draw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility(state, player=1):\n",
    "    \"\"\"check is a state is terminal and return the utility if it is. None means not a terminal mode.\"\"\"\n",
    "    goal = check_win(state, player)\n",
    "    \n",
    "    if goal == 'win': return +1 \n",
    "    if goal == 'draw': return 0\n",
    "    if goal == 'loss': return -1  # loss is failure\n",
    "    if goal == 'next': return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def terminal(state):\n",
    "    '''\n",
    "    Checks if there are any moves available on the state received.\n",
    "       \n",
    "    Parameters\n",
    "    ----------\n",
    "    state: dict\n",
    "        the board\n",
    "    Returns a boolean\n",
    "    '''\n",
    "    \n",
    "    return check_win(state) != 'next'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actions(state):\n",
    "    '''\n",
    "    Returns all possible moves available on the state received.\n",
    "       \n",
    "    Parameters\n",
    "    ----------\n",
    "    state: dict\n",
    "        the board\n",
    "    Returns a list\n",
    "    '''\n",
    "    \n",
    "    if terminal(state):\n",
    "        return []\n",
    "    \n",
    "    # Get a list of all possible actions\n",
    "    actions = []\n",
    "    dots = state['n']*state['m']\n",
    "    \n",
    "    # Check all dots and orientations\n",
    "    for row in range(state['n']):\n",
    "        for col in range(state['m']):\n",
    "            if ('v', row+1, col+1) not in state and (row+1) > 1:\n",
    "                actions.append(('v', row+1, col+1))\n",
    "            if ('h', row+1, col+1) not in state and (col+1) < (state['m']):\n",
    "                # print('Column: ', col+1, ' M: ', state['m'])\n",
    "                actions.append(('h', row+1, col+1))\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement an agent that plays randomly. Make sure the agent function receives as the percept the board and returns a valid action. Use an agent function definition with the following signature (arguments):\n",
    "\n",
    "`def random_player(board, player = None): ...`\n",
    "\n",
    "The argument `player` is used for agents that do not store what side they are playing. The value passed on by the environment should be 1 ot -1 for playerred and yellow, respectively.  See [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_player(state, player = None):\n",
    "    '''\n",
    "    Random agent. Returns a random action from a list of all possible actions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    board: dict\n",
    "        The board\n",
    "    player: int\n",
    "        Player making the move\n",
    "    '''\n",
    "    moves = actions(state)\n",
    "    if len(moves) == 0:\n",
    "        return None\n",
    "    \n",
    "    index = np.random.choice(len(moves))\n",
    "    return moves[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(one, opponent, N = 1, verbose=0):\n",
    "    \"\"\"Play N games. one and opponent are the players' agent functions.\"\"\"\n",
    "    \n",
    "    results = {1: 0, -1: 0, 'draw': 0}\n",
    "    \n",
    "    for i in range(N):\n",
    "        board = empty_board()\n",
    "        player, agent = 1, one\n",
    "        \n",
    "        while True:\n",
    "            # Check the action the player wants to make\n",
    "            action = agent(board, player)\n",
    "            # print(action)\n",
    "                        \n",
    "            # Make the move\n",
    "            board = result(board, action, player)\n",
    "            \n",
    "            # Check if the game is over by checking if there are any moves available\n",
    "            if actions(board) == []:\n",
    "                # If yes, add point to winner and break\n",
    "                win = check_win(board, player)\n",
    "                \n",
    "                if win == 'win':\n",
    "                    results[player] += 1\n",
    "                elif win == 'loss':\n",
    "                    results[-player] += 1\n",
    "                else:\n",
    "                    results['draw'] += 1\n",
    "                if verbose>0: print_board(board)\n",
    "                break\n",
    "            \n",
    "            # Else if player didn't close a box, switch player and continue\n",
    "            if closed_box(board, action) == False:\n",
    "                if player == 1:\n",
    "                    player, agent = -1, opponent\n",
    "                else:\n",
    "                    player, agent = 1, one\n",
    "            # Else, continue\n",
    "            if verbose>1: print_board(board)\n",
    "            \n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let two random agents play against each other 1000 times. Look at the [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) to see how the environment uses the agent functions to play against each other.\n",
    "\n",
    "How often does each player win? Is the result expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 497.2\n",
      "-1: 502.8\n",
      "draw: 0.0\n",
      "Proportion for One:  0.4972\n",
      "Proportion for Opponent:  0.5028\n"
     ]
    }
   ],
   "source": [
    "oneAvg = 0\n",
    "opponentAvg = 0\n",
    "drawAvg = 0\n",
    "\n",
    "for i in range(10):\n",
    "    curr = play(random_player, random_player, 1000)\n",
    "    oneAvg += curr[1]\n",
    "    opponentAvg += curr[-1]\n",
    "    drawAvg += curr['draw']\n",
    "\n",
    "oneAvg = oneAvg/10\n",
    "opponentAvg = opponentAvg/10\n",
    "drawAvg = drawAvg/10\n",
    "print('1:', oneAvg)\n",
    "print('-1:', opponentAvg)\n",
    "print('draw:', drawAvg)\n",
    "print('Proportion for One: ', oneAvg/(oneAvg+opponentAvg+drawAvg))\n",
    "print('Proportion for Opponent: ', opponentAvg/(oneAvg+opponentAvg+drawAvg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is as expected. The win ratio for the players can be approximated as 50/50 and always returns a consistent win/loss ratio regarding the first and second players.<br/>\n",
    "The results suggest there is no real advatange in starting first or not in regards to probabilities of winning if both players are choosing actions randomly.<br/>\n",
    "It also does not return any draws. However, that is also expected because, nearing the end of the game, almost all remaining lines will close a box. Since the environment only switches players if the current player didn't close a box, that player will close many boxes in a row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimax Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "DEBUG = 0\n",
    "COUNT = 0\n",
    "\n",
    "def minimax_search(state, player=1):\n",
    "    global DEBUG, COUNT\n",
    "    COUNT = 0\n",
    "    \n",
    "    val, move = max_value(state, player)\n",
    "    \n",
    "    if DEBUG >= 1: print(f\"Number of nodes searched: {COUNT}\") \n",
    "    \n",
    "    return {'move': move, 'value': val}\n",
    "\n",
    "def max_value(state, player):\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "    \n",
    "    # return utility of state if it is a terminal state\n",
    "    v = utility(state, player)\n",
    "    if DEBUG >= 2: print(\"max in: \" + str(state) + str([v]) ) \n",
    "    if v is not None: return v, None\n",
    "    \n",
    "    v, move = -math.inf, None\n",
    "    \n",
    "     # check all possible actions in the state, return move with the largest value\n",
    "    for a in actions(state):\n",
    "        # print_board(state)\n",
    "        \n",
    "        v2, a2 = min_value(result(state, a, player), player)\n",
    "        if v2 > v:\n",
    "            v, move = v2, a\n",
    "    \n",
    "    if DEBUG >= 2: print(\"max out: \" + str(state) + str([v, move]) ) \n",
    "    return v, move\n",
    "\n",
    "def min_value(state, player):\n",
    "    \"\"\"opponent's best response.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "    \n",
    "    # return utility of state if it is a terminal state\n",
    "    v = utility(state, player)\n",
    "    if DEBUG >= 2: print(\"min in: \" + str(state) + str([v]) ) \n",
    "    if v is not None: return v, None\n",
    "    \n",
    "    v, move = +math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, return move with the smallest value\n",
    "    for a in actions(state):\n",
    "        v2, a2 = max_value(result(state, a, -player), player)\n",
    "        if v2 < v:\n",
    "            v, move = v2, a\n",
    "    \n",
    "    if DEBUG >= 2: print(\"min out: \" + str(state) + str([v, move])) \n",
    "    return v, move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Minimax Search with Alpha-Beta Pruning [30 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the search starting.\n",
    "\n",
    "Implement the search starting from a given board and specifying the player and put it into an agent function.\n",
    "You can use code from the [tic-tac-toe example](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_alpha_beta_tree_search.ipynb).\n",
    "\n",
    "__Notes:__ \n",
    "* Make sure that all your agent functions have a signature consistent with the random agent above.\n",
    "* The search space for larger board may be too large. You can experiment with smaller boards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "DEBUG = -1\n",
    "COUNT = 0\n",
    "\n",
    "def alpha_beta_search(state, player=1):\n",
    "    global DEBUG, COUNT\n",
    "    COUNT = 0\n",
    "    \n",
    "    val, move = max_value_ab(state, player, -math.inf, math.inf)\n",
    "    \n",
    "    if DEBUG >= 0: print(f\"Number of nodes searched: {COUNT}\") \n",
    "    \n",
    "    return {'move': move, 'value': val}\n",
    "\n",
    "def max_value_ab(state, player, alpha, beta):\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "    \n",
    "    # return utility of state if it is a terminal state\n",
    "    v = utility(state, player)\n",
    "    \n",
    "    if DEBUG >= 2: print(f\"max: {state} [alpha,beta]=[{alpha},{beta}] v={v}\")\n",
    "    \n",
    "    if DEBUG >= 2: print(\"max in: \" + str(state) + str([v]) ) \n",
    "    if v is not None: \n",
    "        if DEBUG >= 3: print(f\"     found terminal state. backtracking.\")\n",
    "        if DEBUG >= 0: print('Value: ', v)\n",
    "        return v, None\n",
    "    \n",
    "    v, move = -math.inf, None\n",
    "    \n",
    "    # check all possible actions in the state, return move with the largest value\n",
    "    for a in actions(state):\n",
    "        # print_board(state)\n",
    "        v2, a2 = min_value_ab(result(state, a, player), player, alpha, beta)\n",
    "        \n",
    "        if DEBUG >= 2: print(f\"max: {state} (backtracked) [alpha,beta]=[{alpha},{beta}] v={v2}\")\n",
    "        \n",
    "        if v2 > v:\n",
    "            v, move = v2, a\n",
    "            alpha = max(alpha, v)\n",
    "        if v >= beta:\n",
    "            if DEBUG >= 2: print(f\"     v>=beta ({v}>={beta}): pruning remaining subtree (actions). backtracking.\")\n",
    "            return v, move\n",
    "    \n",
    "    return v, move\n",
    "\n",
    "def min_value_ab(state, player, alpha, beta):\n",
    "    \"\"\"opponent's best response.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "    \n",
    "    # return utility of state if it is a terminal state\n",
    "    v = utility(state, player)\n",
    "    \n",
    "    if DEBUG >= 2: print(f\"min: {state} [alpha,beta]=[{alpha},{beta}] v={v}\")\n",
    "\n",
    "    if v is not None: \n",
    "        if DEBUG >= 3: print(f\"     found terminal state. backtacking.\")\n",
    "        if DEBUG >= 0: print('Value: ', v)\n",
    "        return v, None\n",
    "    \n",
    "    v, move = +math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, return move with the smallest value\n",
    "    for a in actions(state):\n",
    "        v2, a2 = max_value_ab(result(state, a, -player), player, alpha, beta)\n",
    "        \n",
    "        if DEBUG >= 2: print(f\"min: {state} (backtracked) [alpha,beta]=[{alpha},{beta}] v={v2}\")\n",
    "        \n",
    "        if v2 < v:\n",
    "            v, move = v2, a\n",
    "            beta = min(beta, v)\n",
    "        \n",
    "        if v <= alpha:\n",
    "            if DEBUG >= 2: print(f\"     v<=alpha ({v}<={alpha}): pruning remaining subtree (actions). backtracking.\")\n",
    "            return v, move\n",
    "    \n",
    "    return v, move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments\n",
    "Experiment with some manually created boards (at least 5) to check if the agent spots winning opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "         -1: 1\n",
      "          1: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value:  0\n",
      "Value:  -1\n",
      "Value:  1\n",
      "Value:  0\n",
      "Value:  -1\n",
      "Value:  -1\n",
      "Value:  1\n",
      "Value:  1\n",
      "Value:  1\n",
      "Value:  -1\n",
      "Number of nodes searched: 21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'move': ('h', 1, 2), 'value': -1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 2.01 ms\n"
     ]
    }
   ],
   "source": [
    "# Boards\n",
    "DEBUG = 0\n",
    "test1 = empty_small()\n",
    "draw_line(test1, 'h', 3, 1, 1)\n",
    "draw_line(test1, 'h', 3, 2, 1)\n",
    "draw_line(test1, 'h', 2, 1, 1)\n",
    "draw_line(test1, 'h', 2, 2, 1)\n",
    "draw_line(test1, 'h', 1, 1, 1)\n",
    "draw_line(test1, 'v', 3, 1, 1)\n",
    "draw_line(test1, 'v', 2, 1, 1)\n",
    "draw_line(test1, 'v', 2, 2, -1)\n",
    "# draw_line(test1, 'v', 2, 3, 1)\n",
    "# There is no win for 1 (blue) in this situation\n",
    "# Best move: (v, 3, 2)\n",
    "# Other moves: (v, 2, 3), (h, 1, 2), (v, 3, 3)\n",
    "print_board(test1)\n",
    "%time display(alpha_beta_search(test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "         -1: 0\n",
      "          1: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAMIUlEQVR4nO3bT2gchxXH8d9bZSCZqEMO9sE0SQVbCIQgaiRKIW4iAoEopx58KUinwB7WFMf40HMKPaq6tBdDAg2EXDYphbCXHGwHQf6tgrM4fw7egyHQEocQVepetub14I0V29LurP7svNn9fmCI4x1vHnmar4b1yNxdAIC4KkUPAAAYjFADQHCEGgCCI9QAEByhBoDgHjqONz1x4oTPzc0dx1sDwETa3Nz8zt1P7vXasYR6bm5OrVbrON4aACaSmd3c7zU++gCA4Ag1AARHqAEgOEINAMERagAIjlADQHCEGgCCI9QAEByhBoDgCDUABEeoASA4Qg0AwRFqAAiOUANAcIQaAIIj1AAQHKEGgOAINQAER6gBIDhCDQDBEWoACI5QA0BwhBoAgiPUABAcoQaA4Ag1AARHqAEgOEINAMERagAIjlADQHCEOodOp6N6va4sy1SpVJRlmer1ujqdTtGjIQf2V27sT5K7DzwkPSzpE0mfS/pC0mvD/szCwoJPimaz6WmaepIkLunukSSJp2nqzWaz6BExAPsrt2nan6SW79NUu/P6/szMJD3q7jtmlkjakHTe3T/a788sLi56q9U63HeQADqdjubn59Xtdvc9J01TtdttVavVMU6GPNhfuU3b/sxs090X93pt6Ecf/djv9P816R+D6z4h1tbW1Ov1Bp7T6/W0vr4+pokwCvZXbuxv19A7akkysxlJm5J+Kelv7v7HQedPyh11lmXa3t7Odd7W1tYYJsIo8u5vZmZGZ86cGcNEGMXGxoZu37499LxJuf4G3VHnCvVP3ugxSf+Q9Ad3v37fazVJNUl68sknF27evHnggaOoVCrK8/+nUqnk+oLCeO29v0zS6SLGwaFdk/SIpH/f87uTcv0NCvVDo7yRu/9gZpclvSTp+n2vXZJ0SbpzR33AWUOZnZ3NdUc2Ozs7hmkwqr33d1rSlQKmweEt9f95b6in4fob+hm1mZ3s30nLzB6R9KKkr495rhBWVlaUJMnAc5Ik0erq6pgmwijy7A/lNi3XX57nqE9JumxmbUmfSnrf3d873rFiuHjxYq5QX7hwYUwTYRR59odym5brL89TH213P+3u8+7+jLv/aRyDRVCtVtVoNJSm6QMXfJIkStNUjUZjIh4NmkSD9odym7brj59MHGJ5eVntdlu1Wu2en4yq1Wpqt9taXl4uekQM8NP9zczMFD0OjsA0Xn8jPfWR16Q8nofJsrS0pKtXJf4ysayWJEnuVwqd4rgc6gdeAADFItQAEByhBoDgCDUABEeoASA4Qg0AwRFqAAiOUANAcIQaAIIj1AAQHKEGgOAINQAER6gBIDhCDQDBEWoACI5QA0BwhBoAgiPUABAcoQaA4Ag1AARHqAEgOEINAMERagAIjlADQHCEGgCCI9QAEByhBoDgCDUABEeoASA4Qg0AwRFqAAiOUANAcIQaAIIj1AAQHKEGgOAINQAER6gBIDhCDQDBEWoACI5QA0BwhBoAgiPUABAcoQaA4Ag1AARHqAEgOEINAMERagAIjlADQHCEGgCCI9QAEByhBoDgCDUABEeoASA4Qg0AwRFqAAiOUANAcIQaAIIj1AAQHKEGgOAINQAER6hz6HQ6qtfryrJMlUpFWZapXq+r0+kUPRpy+HF/GxsbRY+CIzCV15+7H/mxsLDgk6LZbHqapp4kiUu6eyRJ4mmaerPZLHpEDPDg/p53yTlKeTzfPybz+pPU8n2aOvSO2syeMLPLZvalmX1hZueP91tHHJ1OR2fPnlW321Wv17vntV6vp263q7Nnz07Xd/YSGbQ/lNu0XX95Pvr4n6SL7v60pN9IOmdmTx/vWDGsra0NvcB7vZ7W19fHNBFGkWd/KLdpuf7szh33CH/A7J+S/uru7+93zuLiordarcPOVrgsy7S9vT30vJmZGZ05c2YME2EUGxsbun379n2/W5H02yLGwaF9KCmR9N97fjfLMm1tbRUy0VEys013X9zrtZH+MtHM5iSdlvTxHq/VzKxlZq1bt24daNBodnZ2cp33YAwQAXuZRA/eWOa9Tsss9x21mc1Kuirpz+7+7qBzp+2OelK+o08a9ldu07a/Q99Rm1ki6R1Jbw2L9CRZWVlRkiQDz0mSRKurq2OaCKNgf+XG/nYNvaM2M5P0d0nfu/ured50Uu6oO52O5ufn1e129z0nTVO1221Vq9UxToY82F+5Tdv+DntH/aykVUkvmNm1/vHykU4YVLVaVaPRUJqmD3xnT5JEaZqq0WhMxBfJJGJ/5cb+fmK/B6wPc0zSD7y4u9+4ccPPnTvnMzMzLsmzLPNz5875jRs3ih4NObC/cpuW/WnAD7yM/HheHpPy0cf9lpaWJElXrlwpdA4cDPsrt0nf35E9ngcAGD9CDQDBEWoACI5QA0BwhBoAgiPUABAcoQaA4Ag1AARHqAEgOEINAMERagAIjlADQHCEGgCCI9QAEByhBoDgCDUABEeoASA4Qg0AwRFqAAiOUANAcIQaAIIj1AAQHKEGgOAINQAER6gBIDhCDQDBEWoACI5QA0BwhBoAgiPUABAcoQaA4Ag1AARHqAEgOEINAMERagAIjlADQHCEGgCCI9QAEByhBoDgCDUABEeoASA4Qg0AwRFqAAiOUANAcIQaAIIj1AAQHKEGgOAINQAER6gBIDhCDQDBEWoACI5QA0BwhBoAgiPUABAcoQaA4Ag1AARHqAEgOEINAMERagAIjlADQHCEGgCCI9Q5dDod1et1bWxs6OrVq8qyTPV6XZ1Op+jRkAP7Kzf2J8ndBx6S3pD0raTrw8798VhYWPBJ0Ww2PU1TT5LEJd09kiTxNE292WwWPSIGYH/lNk37k9TyfZpqd17fn5k9J2lH0pvu/kye+C8uLnqr1TrQN45IOp2O5ufn1e129z0nTVO1221Vq9UxToY82F+5Tdv+zGzT3Rf3em3oRx/u/oGk7498qhJYW1tTr9cbeE6v19P6+vqYJsIo2F+5sb9dQ++oJcnM5iS9N2131FmWaXt7O9d5W1tbY5gIo2B/5TZt+zvUHfUI/5GambXMrHXr1q2jettC7ezsHOl5GC/2V27sb9eRhdrdL7n7orsvnjx58qjetlCzs7NHeh7Gi/2VG/vbxeN5A6ysrChJkoHnJEmi1dXVMU2EUbC/cmN/u4aG2szelvShpKfM7Bsze+X4x4rh4sWLub5QLly4MKaJMAr2V27sb1eepz5+7+6n3D1x98fd/fVxDBZBtVpVo9FQmqYPfMEkSaI0TdVoNCbi0aBJxP7Kjf3t4qOPIZaXl9Vut1Wr1ZRlmSqVirIsU61WU7vd1vLyctEjYgD2V27s745cj+eNalIezwOAcRnL43kAgONBqAEgOEINAMERagAIjlADQHCEGgCCI9QAEByhBoDgCDUABEeoASA4Qg0AwRFqAAiOUANAcIQaAIIj1AAQHKEGgOAINQAER6gBIDhCDQDBEWoACI5QA0BwhBoAgiPUABAcoQaA4Ag1AARHqAEgOEINAMERagAIjlADQHDm7kf/pma3JN088jeO4YSk74oeAgfG/sptkvf3C3c/udcLxxLqSWZmLXdfLHoOHAz7K7dp3R8ffQBAcIQaAIIj1KO7VPQAOBT2V25TuT8+owaA4LijBoDgCDUABEeoczKzN8zsWzO7XvQsGJ2ZPWFml83sSzP7wszOFz0T8jGzh83sEzP7vL+714qeadz4jDonM3tO0o6kN939maLnwWjM7JSkU+7+mZn9TNKmpN+5+5cFj4YhzMwkPeruO2aWSNqQdN7dPyp4tLHhjjond/9A0vdFz4GDcfd/uftn/V9vS/pK0s+LnQp5+B07/X9N+sdU3WESakwdM5uTdFrSxwWPgpzMbMbMrkn6VtL77j5VuyPUmCpmNivpHUmvuvt/ip4H+bj7bXf/laTHJf3azKbq40dCjanR/3zzHUlvufu7Rc+D0bn7D5IuS3qp4FHGilBjKvT/Qup1SV+5+1+Kngf5mdlJM3us/+tHJL0o6etChxozQp2Tmb0t6UNJT5nZN2b2StEzYSTPSlqV9IKZXesfLxc9FHI5JemymbUlfao7n1G/V/BMY8XjeQAQHHfUABAcoQaA4Ag1AARHqAEgOEINAMERagAIjlADQHD/B/Rr+u6pAPkOAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'move': ('h', 1, 1), 'value': 1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 996 Âµs\n"
     ]
    }
   ],
   "source": [
    "test2 = empty_small()\n",
    "draw_line(test2, 'h', 3, 2, 1)\n",
    "draw_line(test2, 'h', 2, 1, 1)\n",
    "draw_line(test2, 'h', 2, 2, 1)\n",
    "draw_line(test2, 'v', 3, 2, 1)\n",
    "draw_line(test2, 'v', 3, 3, 1)\n",
    "draw_line(test2, 'v', 2, 1, 1)\n",
    "draw_line(test2, 'v', 2, 2, 1)\n",
    "draw_line(test2, 'v', 2, 3, 1)\n",
    "# Possible win for 1 (blue) in this situation\n",
    "# Best moves: (h, 1, 1), (h, 1, 2)\n",
    "# Bad moves: (v, 3, 1), (h, 3, 1)\n",
    "print_board(test2)\n",
    "%time display(alpha_beta_search(test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "         -1: 0\n",
      "          1: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'move': ('v', 2, 3), 'value': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 1.32 ms\n"
     ]
    }
   ],
   "source": [
    "test3 = empty_small()\n",
    "draw_line(test3, 'h', 3, 1, -1)\n",
    "draw_line(test3, 'h', 3, 2, 1)\n",
    "draw_line(test3, 'h', 2, 1, -1)\n",
    "draw_line(test3, 'h', 2, 2, 1)\n",
    "draw_line(test3, 'h', 1, 2, -1)\n",
    "draw_line(test3, 'v', 3, 2, 1)\n",
    "draw_line(test3, 'v', 2, 2, -1)\n",
    "# Best moves: (v, 3, 1), (v, 3, 3), (v, 2, 3)\n",
    "# Bad moves: (v, 2, 1), (h, 1, 1)\n",
    "print_board(test3)\n",
    "%time display(alpha_beta_search(test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "         -1: 0\n",
      "          1: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAMa0lEQVR4nO3bT2gchxXH8d/TeiCeqNMe7INpkgq2EAhBxEiUQkQiAoEopx58KUingA5rimN86DmFHlVd2oshgQZCLpuUQthLDpbCQv6tg7M4fw7egyHQEocQVUKHbsXrwUqc2KvdWf3ZeTv7/cBiWzvaPPI0X43XI3N3AQDimip6AABAf4QaAIIj1AAQHKEGgOAINQAEd+okXvTMmTM+MzNzEi8NAKV0/fr1b9z9bK/nTiTUMzMzarVaJ/HSAFBKZnb7oOd46wMAgiPUABAcoQaA4Ag1AARHqAEgOEINAMERagAIjlADQHCEGgCCI9QAEByhBoDgCDUABEeoASA4Qg0AwRFqAAiOUANAcIQaAIIj1AAQHKEGgOAINQAER6gBIDhCDQDBEWoACI5QA0BwhBoAgiPUABAcoQaA4Ag1AARHqAEgOEINAMER6hw6nY5qtZqyLNPU1JSyLFOtVlOn0yl6NOTA/sYb+5Pk7n0fkh6S9JGkTyV9JumVQZ8zNzfnZdFoNDxNU0+SxCX98EiSxNM09UajUfSI6IP9jbdJ2p+klh/QVLv7/MHMzCQ97O47ZpZIakq65O4fHPQ58/Pz3mq1jvYdJIBOp6PZ2Vnt7u4eeEyapmq326pWqyOcDHmwv/E2afszs+vuPt/ruYFvfezHfmf/j8n+o3/dS2JtbU3dbrfvMd1uV+vr6yOaCMNgf+ON/d0z8IpaksysIum6pF9L+pu7/7Hf8WW5os6yTNvb2wOPq1QqWlhYGMFEGEaz2dTe3t7A47Is09bW1ggmwjDynn9l2V+/K+pcof7RC/1C0j8k/cHdb9733KqkVUl67LHH5m7fvn3ogaOYmprSg/9/MknnixgHR3ZD0mlJ//7JR6empnIFHaPV+/zrfVwZ9tcv1KeGeSF3/87Mrkl6QdLN+567KumqdPeK+pCzhjI9Pd3jO/p5SRsFTIOjW9z/9aehnp6eHvkkGKz3+df7uLIb+B61mZ3dv5KWmZ2W9LykL094rhCWl5eVJEnRY+AEJUmilZWVosdAD3nOv0nZX577qM9JumZmbUkfS3rX3d852bFiuHLlCqEuuSRJdPny5aLHQA95zr9J2V+euz7a7n7e3Wfd/Ul3/9MoBougWq2qXq8rTVOCXTJJkihNU9Xr9VLc2lVG/c6/SdsfP5k4wNLSktrttlZXV1WpVIoeB8cgyzKtrq6q3W5raWmp6HHQR6/zbxL3N9RdH3mV5fa8+y0uLmpzU+IfE8fVoiTJfaPQKXA4i4uLkqSNjY1C5zgpR/qBFwBAsQg1AARHqAEgOEINAMERagAIjlADQHCEGgCCI9QAEByhBoDgCDUABEeoASA4Qg0AwRFqAAiOUANAcIQaAIIj1AAQHKEGgOAINQAER6gBIDhCDQDBEWoACI5QA0BwhBoAgiPUABAcoQaA4Ag1AARHqAEgOEINAMERagAIjlADQHCEGgCCI9QAEByhBoDgCDUABEeoASA4Qg0AwRFqAAiOUANAcIQaAIIj1AAQHKEGgOAINQAER6gBIDhCDQDBEWoACI5QA0BwhBoAgiPUABAcoQaA4Ag1AARHqAEgOEINAMERagAIjlADQHCEGgCCI9QAEByhBoDgCDUABEeoASA4Qg0AwRHqHDqdjmq1mprNZtGj4BhkWaZaraZOp1P0KMjhx+ff5ubmZO7P3Y/9MTc352XRaDQ8TVNPksQlufSsS85jLB/P7j/kSZJ4mqbeaDSK/hJDHw+efyrt/iS1/ICmDryiNrNHzeyamX1uZp+Z2aWT/dYRR6fT0YULF7S7u6tut1v0ODhG3W5Xu7u7unDhwmRdmY2RfuffpO0vz1sf/5N0xd2fkPRbSRfN7ImTHSuGtbU1Al1y3W5X6+vrRY+BHvKcf5OyP7t7xT3EJ5j9U9Jf3f3dg46Zn5/3Vqt11NkKl2WZtre37/vozyU9VcA0OLr393/9708+WqlUtLCwMPpx0Fez2dTe3t7A47Is09bW1ggmOllmdt3d53s9N9Q/JprZjKTzkj7s8dyqmbXMrHXnzp1DDRrNzs5Oj4+eHvkcOC6JpFMPfDRPDDB6effS+zwtl9xX1GY2LWlT0p/d/e1+x5b7irr3cWX4jl427G+8Tdr+jnxFbWaJpLckvTEo0mWyvLysJEn6HpMkiVZWVkY0EYbB/sYb+7tn4BW1mZmkv0v61t1fzvOiZbmi7nQ6mp2d1e7u7oHHpGmqdrutarU6wsmQB/sbb5O2v6NeUT8taUXSc2Z2Y//x4rFOGFS1WlW9Xleapg98Z0+SRGmaql6vl+KLpIzY33hjfz9y0A3WR3mU6Qde3N1v3brlFy9e9CzLfGpqyrMs84sXL/qtW7eKHg05sL/x9v3+KpWKSyrt/tTnB16Gvj0vj7K89QEgjsXFRUnSxsZGoXOclGO7PQ8AMHqEGgCCI9QAEByhBoDgCDUABEeoASA4Qg0AwRFqAAiOUANAcIQaAIIj1AAQHKEGgOAINQAER6gBIDhCDQDBEWoACI5QA0BwhBoAgiPUABAcoQaA4Ag1AARHqAEgOEINAMERagAIjlADQHCEGgCCI9QAEByhBoDgCDUABEeoASA4Qg0AwRFqAAiOUANAcIQaAIIj1AAQHKEGgOAINQAER6gBIDhCDQDBEWoACI5QA0BwhBoAgiPUABAcoQaA4Ag1AARHqAEgOEINAMERagAIjlADQHCEGgCCI9QAEByhBoDgCDUABEeoASA4Qg0AwRFqAAiOUANAcIQaAIIj1AAQHKEGgOAINQAER6hz6HQ6qtVqyrJMU1NTyrJMtVpNnU6n6NGQA/sbb9/vr9lsanNzczL35+59H5Jek/S1pJuDjv3+MTc352XRaDQ8TVNPksQl/fBIksTTNPVGo1H0iOiD/Y23SdqfpJYf0FS7+/zBzOwZSTuSXnf3J/PEf35+3lut1qG+cUTS6XQ0Ozur3d3dA49J01TtdlvVanWEkyEP9jfeJm1/Znbd3ed7PTfwrQ93f0/St8c+1RhYW1tTt9vte0y329X6+vqIJsIw2N94Y3/3DLyiliQzm5H0zqRdUWdZpu3t7VzHbW1tjWAiDCPv/iqVihYWFkYwEYbRbDa1t7c38LiynH9HuqIe4j+yamYtM2vduXPnuF62UDs7O8d6HEYr717yxACjl3cvk3D+nTquF3L3q5KuSnevqI/rdYs0PT2d64psenp6BNNgWHn3l2WZNjY2Tn4gDCXv34gm4fzj9rw+lpeXlSRJ32OSJNHKysqIJsIw2N94Y3/3DAy1mb0p6X1Jj5vZV2b20smPFcOVK1dyfaFcvnx5RBNhGOxvvLG/e/Lc9fF7dz/n7om7P+Lur45isAiq1arq9brSNH3gCyZJEqVpqnq9Xopbg8qI/Y039ncPb30MsLS0pHa7rdXV1Z/8ZNvq6qra7baWlpaKHhF9sL/xxv7uynV73rDKcnseAIzKSG7PAwCcDEINAMERagAIjlADQHCEGgCCI9QAEByhBoDgCDUABEeoASA4Qg0AwRFqAAiOUANAcIQaAIIj1AAQHKEGgOAINQAER6gBIDhCDQDBEWoACI5QA0BwhBoAgiPUABAcoQaA4Ag1AARHqAEgOEINAMERagAIjlADQHCEGgCCM3c//hc1uyPp9rG/cAxnJH1T9BA4NPY33sq8v1+5+9leT5xIqMvMzFruPl/0HDgc9jfeJnV/vPUBAMERagAIjlAP72rRA+BI2N94m8j98R41AATHFTUABEeoASA4Qp2Tmb1mZl+b2c2iZ8HwzOxRM7tmZp+b2WdmdqnomZCPmT1kZh+Z2af7u3ul6JlGjfeoczKzZyTtSHrd3Z8seh4Mx8zOSTrn7p+Y2c8kXZf0O3f/vODRMICZmaSH3X3HzBJJTUmX3P2DgkcbGa6oc3L39yR9W/QcOBx3/5e7f7L/+21JX0j6ZbFTIQ+/a2f/j8n+Y6KuMAk1Jo6ZzUg6L+nDgkdBTmZWMbMbkr6W9K67T9TuCDUmiplNS3pL0svu/p+i50E+7r7n7k9JekTSb8xsot5+JNSYGPvvb74l6Q13f7voeTA8d/9O0jVJLxQ8ykgRakyE/X+QelXSF+7+l6LnQX5mdtbMfrH/+9OSnpf0ZaFDjRihzsnM3pT0vqTHzewrM3up6JkwlKclrUh6zsxu7D9eLHoo5HJO0jUza0v6WHffo36n4JlGitvzACA4rqgBIDhCDQDBEWoACI5QA0BwhBoAgiPUABAcoQaA4P4PaVz5bLk0v0EAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'move': ('v', 2, 2), 'value': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 998 Âµs\n"
     ]
    }
   ],
   "source": [
    "test4 = empty_small()\n",
    "draw_line(test4, 'h', 3, 1, -1)\n",
    "draw_line(test4, 'h', 2, 1, 1)\n",
    "draw_line(test4, 'h', 2, 2, -1)\n",
    "draw_line(test4, 'h', 1, 2, 1)\n",
    "draw_line(test4, 'v', 3, 1, -1)\n",
    "draw_line(test4, 'v', 3, 2, 1)\n",
    "draw_line(test4, 'v', 3, 3, -1)\n",
    "draw_line(test4, 'v', 2, 3, -1)\n",
    "# Best moves: (v, 2, 2), (h, 3, 2)\n",
    "# Bad moves: (v, 2, 1), (h, 1, 1)\n",
    "print_board(test4)\n",
    "%time display(alpha_beta_search(test4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "         -1: 2\n",
      "          1: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'move': ('v', 3, 3), 'value': 1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 5 ms\n"
     ]
    }
   ],
   "source": [
    "test5 = empty_board()\n",
    "draw_line(test5, \"h\", 4, 1, -1)\n",
    "draw_line(test5, \"h\", 4, 2, -1)\n",
    "draw_line(test5, \"h\", 4, 3, -1)\n",
    "draw_line(test5, \"h\", 3, 1, -1)\n",
    "draw_line(test5, \"h\", 3, 3, -1)\n",
    "draw_line(test5, \"h\", 2, 1, -1)\n",
    "draw_line(test5, \"h\", 1, 1, -1)\n",
    "draw_line(test5, \"h\", 1, 2, -1)\n",
    "draw_line(test5, \"h\", 1, 3, -1)\n",
    "# draw_line(test5, \"v\", 4, 2, -1)\n",
    "draw_line(test5, \"v\", 4, 3, -1)\n",
    "draw_line(test5, \"v\", 4, 4, -1)\n",
    "draw_line(test5, \"v\", 3, 1, -1)\n",
    "draw_line(test5, \"v\", 3, 4, -1)\n",
    "draw_line(test5, \"v\", 2, 1, -1)\n",
    "draw_line(test5, \"v\", 2, 2, -1)\n",
    "draw_line(test5, \"v\", 2, 3, -1)\n",
    "draw_line(test5, \"v\", 2, 4, -1)\n",
    "# Best moves: (h, 2, 2), (v, 3, 2), (v, 3, 3), (h, 2, 3)\n",
    "# Bad moves: (h, 3, 2), (v, 4, 1), (v, 4, 2), (h, 3, 2)\n",
    "print_board(test5)\n",
    "%time display(alpha_beta_search(test5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "         -1: 0\n",
      "          1: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'move': ('h', 1, 1), 'value': -1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 20.2 s\n",
      "Wall time: 20.2 s\n"
     ]
    }
   ],
   "source": [
    "test6 = empty_board()\n",
    "draw_line(test6, \"h\", 4, 1, -1)\n",
    "draw_line(test6, \"h\", 4, 2, -1)\n",
    "draw_line(test6, \"h\", 4, 3, -1)\n",
    "draw_line(test6, \"h\", 3, 1, -1)\n",
    "draw_line(test6, \"h\", 1, 3, -1)\n",
    "draw_line(test6, \"v\", 4, 4, -1)\n",
    "draw_line(test6, \"v\", 3, 1, -1)\n",
    "draw_line(test6, \"v\", 2, 1, -1)\n",
    "draw_line(test6, \"v\", 2, 2, -1)\n",
    "draw_line(test6, \"v\", 2, 4, -1)\n",
    "\n",
    "print_board(test6)\n",
    "%time display(alpha_beta_search(test6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board make the board larger. What is the largest board you can solve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Alpha Beta Search can process a 3x3 board quickly.<br/>\n",
    "However, that is also the largest board size it can solve in a reasonable time starting with a blank board as even a 4x4 takes too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'move': ('h', 1, 1), 'value': 0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 9.7 s\n",
      "Wall time: 9.71 s\n"
     ]
    }
   ],
   "source": [
    "# 3x3 board\n",
    "DEBUG = -1\n",
    "%time display(alpha_beta_search(empty_small()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4x4 board\n",
    "%time display(alpha_beta_search(empty_board()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move ordering\n",
    "\n",
    "Starting the search with better moves will increase the efficiency of alpha-beta pruning. Describe and implement a simple move ordering strategy. Make a table that shows how the ordering strategies influence the time it takes to make a move?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the best strategies in Dots and Boxes is to make long chains so the player can complete many boxes sequentially, without losing his turn.<br/>\n",
    "An acceptable move ordering is to consider creating a long chain on the left and right sides of the board.<br/>\n",
    "To achieve that ordering, we will modify the `actions` function so it lists the vertical lines first so they can create these side chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "alpha_beta_search(empty_small())\n",
    "end = time.time()\n",
    "no_sort_time1 = end - start\n",
    "\n",
    "start = time.time()\n",
    "alpha_beta_search(test6)\n",
    "end = time.time()\n",
    "no_sort_time2 = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorts by Vertical first\n",
    "def actions(state):\n",
    "    if terminal(state):\n",
    "        return []\n",
    "    \n",
    "    # Get a list of all possible actions\n",
    "    actions = []\n",
    "    dots = state['n']*state['m']\n",
    "    \n",
    "    # Check all dots and orientations\n",
    "    for row in range(state['n']):\n",
    "        for col in range(state['m']):\n",
    "            if ('v', row+1, col+1) not in state and (row+1) > 1:\n",
    "                actions.insert(0, ('v', row+1, col+1))\n",
    "            if ('h', row+1, col+1) not in state and (col+1) < (state['m']):\n",
    "                # print('Column: ', col+1, ' M: ', state['m'])\n",
    "                actions.append(('h', row+1, col+1))\n",
    "    \n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "alpha_beta_search(empty_small())\n",
    "end = time.time()\n",
    "sort_time1 = end - start\n",
    "\n",
    "start = time.time()\n",
    "alpha_beta_search(test6)\n",
    "end = time.time()\n",
    "sort_time2 = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorts by Horizontal first\n",
    "def actions(state):\n",
    "    if terminal(state):\n",
    "        return []\n",
    "    \n",
    "    # Get a list of all possible actions\n",
    "    actions = []\n",
    "    dots = state['n']*state['m']\n",
    "    \n",
    "    # Check all dots and orientations\n",
    "    for row in range(state['n']):\n",
    "        for col in range(state['m']):\n",
    "            if ('v', row+1, col+1) not in state and (row+1) > 1:\n",
    "                actions.append(('v', row+1, col+1))\n",
    "            if ('h', row+1, col+1) not in state and (col+1) < (state['m']):\n",
    "                # print('Column: ', col+1, ' M: ', state['m'])\n",
    "                actions.insert(0, ('h', row+1, col+1))\n",
    "    \n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "alpha_beta_search(empty_small())\n",
    "end = time.time()\n",
    "sort_h_time1 = end - start\n",
    "\n",
    "start = time.time()\n",
    "alpha_beta_search(test6)\n",
    "end = time.time()\n",
    "sort_h_time2 = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No Sorting</th>\n",
       "      <th>Sorting by Vertical</th>\n",
       "      <th>Sorting by Horizontal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.783758</td>\n",
       "      <td>8.109426</td>\n",
       "      <td>11.146569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.071231</td>\n",
       "      <td>20.866912</td>\n",
       "      <td>28.429982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No Sorting  Sorting by Vertical  Sorting by Horizontal\n",
       "0    3.783758             8.109426              11.146569\n",
       "1    7.071231            20.866912              28.429982"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "table = pd.DataFrame({\n",
    "'No Sorting': [no_sort_time1, no_sort_time2],\n",
    "'Sorting by Vertical': [sort_time1, sort_time2],\n",
    "'Sorting by Horizontal': [sort_h_time1, sort_h_time2]\n",
    "}, index=[0, 1])\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above shows that the sortings make the decision slower. So it is wiser to keep going with the original sorting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return to original sorting\n",
    "def actions(state):\n",
    "    if terminal(state):\n",
    "        return []\n",
    "    \n",
    "    # Get a list of all possible actions\n",
    "    actions = []\n",
    "    dots = state['n']*state['m']\n",
    "    \n",
    "    # Check all dots and orientations\n",
    "    for row in range(state['n']):\n",
    "        for col in range(state['m']):\n",
    "            if ('v', row+1, col+1) not in state and (row+1) > 1:\n",
    "                actions.append(('v', row+1, col+1))\n",
    "            if ('h', row+1, col+1) not in state and (col+1) < (state['m']):\n",
    "                # print('Column: ', col+1, ' M: ', state['m'])\n",
    "                actions.append(('h', row+1, col+1))\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first few moves\n",
    "\n",
    "Start with an empty board. This is the worst case scenario for minimax search with alpha-beta pruning since it needs solve all possible games that can be played (minus some pruning) before making the decision. What can you do? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prevent the agent from running all possible games from the start, the agent can insert a couple of random lines so the game gets started. Later, the agent will start calculating the best possible moves when there are fewer nodes to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n': 4,\n",
       " 'm': 4,\n",
       " 1: 0,\n",
       " -1: 0,\n",
       " ('h', 4, 1): True,\n",
       " ('h', 4, 2): True,\n",
       " ('h', 4, 3): True,\n",
       " ('h', 3, 1): True,\n",
       " ('h', 1, 3): True,\n",
       " ('v', 4, 4): True,\n",
       " ('v', 3, 1): True,\n",
       " ('v', 2, 1): True,\n",
       " ('v', 2, 2): True,\n",
       " ('v', 2, 4): True}"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = -1\n",
    "COUNT = 0\n",
    "\n",
    "def alpha_beta_search(state, player=1):\n",
    "    global DEBUG, COUNT\n",
    "    COUNT = 0\n",
    "    \n",
    "    # Check if state has less than 75% of lines drawn\n",
    "    totalLines = ((board['n']-1) * 2) * ((board['m']-1) * 2)\n",
    "    linesDrawn = 0\n",
    "    \n",
    "    for line in state:\n",
    "        if line != 'n' and line != 'm' and type(line) != int:\n",
    "            linesDrawn += 1\n",
    "    \n",
    "    if linesDrawn / totalLines < 0.70:\n",
    "        # Choose a random line\n",
    "        return random_player(state)\n",
    "    \n",
    "    \n",
    "    val, move = max_value_ab(state, player, -math.inf, math.inf)\n",
    "    \n",
    "    if DEBUG >= 0: print(f\"Number of nodes searched: {COUNT}\") \n",
    "    \n",
    "    return {'move': move, 'value': val}\n",
    "\n",
    "def max_value_ab(state, player, alpha, beta):\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "    \n",
    "    # return utility of state if it is a terminal state\n",
    "    v = utility(state, player)\n",
    "    \n",
    "    if DEBUG >= 2: print(f\"max: {state} [alpha,beta]=[{alpha},{beta}] v={v}\")\n",
    "    \n",
    "    if DEBUG >= 2: print(\"max in: \" + str(state) + str([v]) ) \n",
    "    if v is not None: \n",
    "        if DEBUG >= 3: print(f\"     found terminal state. backtracking.\")\n",
    "        if DEBUG >= 0: print('Value: ', v)\n",
    "        return v, None\n",
    "    \n",
    "    v, move = -math.inf, None\n",
    "    \n",
    "    # check all possible actions in the state, return move with the largest value\n",
    "    for a in actions(state):\n",
    "        # print_board(state)\n",
    "        v2, a2 = min_value_ab(result(state, a, player), player, alpha, beta)\n",
    "        \n",
    "        if DEBUG >= 2: print(f\"max: {state} (backtracked) [alpha,beta]=[{alpha},{beta}] v={v2}\")\n",
    "        \n",
    "        if v2 > v:\n",
    "            v, move = v2, a\n",
    "            alpha = max(alpha, v)\n",
    "        if v >= beta:\n",
    "            if DEBUG >= 2: print(f\"     v>=beta ({v}>={beta}): pruning remaining subtree (actions). backtracking.\")\n",
    "            return v, move\n",
    "    \n",
    "    return v, move\n",
    "\n",
    "def min_value_ab(state, player, alpha, beta):\n",
    "    \"\"\"opponent's best response.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "    \n",
    "    # return utility of state if it is a terminal state\n",
    "    v = utility(state, player)\n",
    "    \n",
    "    if DEBUG >= 2: print(f\"min: {state} [alpha,beta]=[{alpha},{beta}] v={v}\")\n",
    "\n",
    "    if v is not None: \n",
    "        if DEBUG >= 3: print(f\"     found terminal state. backtacking.\")\n",
    "        if DEBUG >= 0: print('Value: ', v)\n",
    "        return v, None\n",
    "    \n",
    "    v, move = +math.inf, None\n",
    "\n",
    "    # check all possible actions in the state, return move with the smallest value\n",
    "    for a in actions(state):\n",
    "        v2, a2 = max_value_ab(result(state, a, -player), player, alpha, beta)\n",
    "        \n",
    "        if DEBUG >= 2: print(f\"min: {state} (backtracked) [alpha,beta]=[{alpha},{beta}] v={v2}\")\n",
    "        \n",
    "        if v2 < v:\n",
    "            v, move = v2, a\n",
    "            beta = min(beta, v)\n",
    "        \n",
    "        if v <= alpha:\n",
    "            if DEBUG >= 2: print(f\"     v<=alpha ({v}<={alpha}): pruning remaining subtree (actions). backtracking.\")\n",
    "            return v, move\n",
    "    \n",
    "    return v, move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime\n",
    "\n",
    "Let the Minimax Search agent play a random agent on a small board. Analyze wins, losses and draws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\diogo\\OneDrive\\Desktop\\SMU\\AI\\Dots and Boxes\\assignment_dots_and_boxes.ipynb Cell 56'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/diogo/OneDrive/Desktop/SMU/AI/Dots%20and%20Boxes/assignment_dots_and_boxes.ipynb#ch0000043?line=0'>1</a>\u001b[0m play(alpha_beta_search, random_player, empty_board())\n",
      "\u001b[1;32mc:\\Users\\diogo\\OneDrive\\Desktop\\SMU\\AI\\Dots and Boxes\\assignment_dots_and_boxes.ipynb Cell 20'\u001b[0m in \u001b[0;36mplay\u001b[1;34m(one, opponent, N, verbose)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/diogo/OneDrive/Desktop/SMU/AI/Dots%20and%20Boxes/assignment_dots_and_boxes.ipynb#ch0000019?line=1'>2</a>\u001b[0m \u001b[39m\"\"\"Play N games. one and opponent are the players' agent functions.\"\"\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/diogo/OneDrive/Desktop/SMU/AI/Dots%20and%20Boxes/assignment_dots_and_boxes.ipynb#ch0000019?line=3'>4</a>\u001b[0m results \u001b[39m=\u001b[39m {\u001b[39m1\u001b[39m: \u001b[39m0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m: \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdraw\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0\u001b[39m}\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/diogo/OneDrive/Desktop/SMU/AI/Dots%20and%20Boxes/assignment_dots_and_boxes.ipynb#ch0000019?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39;49m(N):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/diogo/OneDrive/Desktop/SMU/AI/Dots%20and%20Boxes/assignment_dots_and_boxes.ipynb#ch0000019?line=6'>7</a>\u001b[0m     board \u001b[39m=\u001b[39m empty_board()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/diogo/OneDrive/Desktop/SMU/AI/Dots%20and%20Boxes/assignment_dots_and_boxes.ipynb#ch0000019?line=7'>8</a>\u001b[0m     player, agent \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m, one\n",
      "\u001b[1;31mTypeError\u001b[0m: 'dict' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "play(alpha_beta_search, random_player, empty_board())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Heuristic Alpha-Beta Tree Search [30 points] \n",
    "\n",
    "### Heuristic evaluation function\n",
    "\n",
    "Define and implement a heuristic evaluation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An acceptable Heuristic Function can evaluate if the line will become the third line of a box. We want to avoid this situation because the opponent will be able to close that newly formed almost completed box and score a point on us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cutting off search \n",
    "\n",
    "Modify your Minimax Search with Alpha-Beta Pruning to cut off search at a specified depth and use the heuristic evaluation function. Experiment with different cutoff values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with the same manually created boards as above to check if the agent spots winning opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime\n",
    "\n",
    "Let two heuristic search agents (different cutoff depth, different heuristic evaluation function) compete against each other on a reasonably sized board. Since there is no randomness, you only need to let them play once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tournament task [+1 to 5% bonus on your course grade; will be assigned separately]\n",
    "\n",
    "Find another student and let your best agent play against the other student's best player. You are allowed to use any improvements you like as long as you code it yourself. We will set up a class tournament on Canvas. This tournament will continue after the submission deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graduate student advanced task: Pure Monte Carlo Search and Best First Move [10 point]\n",
    "\n",
    "__Undergraduate students:__ This is a bonus task you can attempt if you like [+5 Bonus point].\n",
    "\n",
    "### Pure Monte Carlo Search\n",
    "\n",
    "Implement Pure Monte Carlo Search (see [tic-tac-toe-example](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_pure_monte_carlo_search.ipynb)) and investigate how this search performs on the test boards that you have used above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best First Move\n",
    "\n",
    "How would you determine what the best first move for a standard board ($5 \\times 5$) is? You can use Pure Monte Carlo Search or any algorithms that you have implemented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
